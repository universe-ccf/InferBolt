# Voicery · 架构设计文档

> 目标：一个可搜索与对话的“角色扮演 + 语音”应用。支持文本与语音双链路、多轮记忆、技能路由（思辨类 & 关怀类 & 教学类），并与七牛云端大模型兼容接口对接（LLM / ASR / TTS）。

---

## 1. 总体架构




**数据流：**

- **文本链路**：UI → `respond()` →（路由）→ 普通对话或技能 → LLM → 更新 `SessionState.messages` → UI显示（支持“整段”或“真·流式”）。
- **语音链路**：UI录音 → `respond_voice()`：
  1. `ASRWsClient.transcribe()`（WS帧协议 + gzip + JSON）  
  2. 得到 `user_text` 后复用 `respond()` → LLM  
  3. `TTSClient.synthesize()` → 生成 `wav` → 文件缓存 → 返回路径  
  4. UI 播放（当前版本：**HTML自动播放**；也保留回退：Gradio `gr.Audio`）。

---

## 2. 配置与常量（`config/settings.py`）

- **LLM**：`LLM_MODEL`, `LLM_TEMPERATURE`, `MAX_ROUNDS`, `MAX_TOKENS_RESPONSE`, `API_KEY`, `BASE_URL`
- **ASR/TTS**：`ASR_TRANSPORT=ws`, `ASR_WS_URL`, `TTS_VOICE`, `TTS_ENCODING="wav"`, `TTS_SPEED`
- **超时/重试**：`CONNECT_TIMEOUT`, `READ_TIMEOUT`, `REQUEST_TIMEOUT=(conn,read)`, `HTTP_MAX_RETRIES`, `HTTP_BACKOFF_SEC`
- **语音音频规范化/静音裁剪**：`TTS_SILENCE_DBFS`, `TTS_RMS_WIN_MS`, `TTS_TRIM_PAD_MS`, `TTS_TARGET_SR`
- **技能路由**：`SKILL_CANDIDATES`、`SKILL_DESCRIPTIONS`、`INTENT_CONF_THRESHOLD`
- **缓存**：`ENABLE_SPEECH_CACHE`, `CACHE_TTS_DIR`, `CACHE_ASR_DIR`
- **日志**：`ENABLE_LOGGING`, `LOG_PATH`, `DEBUG`
- **文本/语音模式细节**：`TEXT_STREAMING`、`MAX_REPLY_CHARS_VOICE`, `SENTENCE_SILENCE_MS`

> **说明**：`MAX_ROUNDS` 决定历史消息的截断窗口（见 §6）。

---

## 3. Core 模块

### 3.1 类型与状态（`core/types.py` & `core/state.py`）

- `Message(role, content, meta={})`
- `TurnResult(reply_text, skill, data, audio_bytes)`
- `SkillResult(name, display_tag, reply_text, data)`
- `RoleConfig(name, style, persona, catchphrases, taboos, format_prefs, mission, tts)`
- `SessionState(session_id, messages=[], last_skill=None)`
- 工具函数：
  - `append_turn(state, user_msg, assistant_msg, max_rounds)`
  - `get_recent_messages(state, max_rounds)`
  - `reset_session(state)`

### 3.2 路由（`core/dispatcher.py`）

- 规则优先（关键词 → skill）
- 未命中：调用 `llm_client.classify(text)`  
  - 返回 `confidence_map`；代码端 `argmax` + 阈值 `INTENT_CONF_THRESHOLD`
- 未达阈值或 `none`：走普通对话

### 3.3 管线（`core/pipeline.py`）

- `build_system_prompt(role)`
- `assemble_messages(system, history, user_text)`
- `run_skill(name, user_text, role, history, llm_client)`
- `respond(user_text, state, role, llm_client)`
- `respond_voice(audio_np, sample_rate, ...)`
- `respond_short(...)`
- `voice_sentence_loop(...)`

---

## 4. Clients

### 4.1 LLM（`clients/llm_client.py`）

- `complete(messages, max_tokens=..., stream=False) -> str`
- `complete_chunks(messages, max_tokens=...) -> Iterable[str]`
- `classify(text) -> dict`

### 4.2 ASR（`clients/asr_ws_client.py`）

- WebSocket 协议：配置帧 → 音频帧 → 结束帧
- 返回 `ASRResult(text, confidence, meta)`

### 4.3 TTS（`clients/tts_client.py`）

- POST `/voice/tts`，返回 base64 音频  
- 处理：RMS → 单声道 → 静音裁剪 → 采样率一致  
- 缓存机制（sha256）  
- 返回 `TTSResult(audio_path, sample_rate, meta)`

---

## 5. Skills（策略层）

- **Socrates**：`steelman`、`x_exam`、`counterfactual`
- **Luma**：`luma_story`、`luma_reframe`、`luma_roleplay`
- **Aris**：`aris_reverse`、`aris_practice`、`aris_bimap`

统一签名：

```python
def run(user_text: str, role: RoleConfig, history: List[Message], llm_client) -> SkillResult
