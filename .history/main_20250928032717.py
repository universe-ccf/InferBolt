# main.py
from __future__ import annotations
import os, io, uuid
import gradio as gr
from clients.llm_client import LLMClient
from core.state import SessionState, reset_session
from core.types import RoleConfig
from core.roles import load_all_roles
import json
import numpy as np
from core.pipeline import respond, respond_voice
from core.pipeline import voice_sentence_loop, respond_short  
from clients.asr_ws_client import ASRWsClient                          
from clients.tts_client import TTSClient                                


SKILL_LABELS = {
    "steelman": "å¼ºåŒ–è®ºè¯",
    "x_exam": "äº¤å‰è´¨è¯¢",
    "counterfactual": "åäº‹å®æŒ‘æˆ˜",
}


# === åŠ è½½è§’è‰²é…ç½®===
ROLES_CACHE = load_all_roles()

def load_role_config(name: str) -> RoleConfig:
    return ROLES_CACHE.get(name, list(ROLES_CACHE.values())[0])

# === å›è°ƒï¼šæ–‡æœ¬è¾“å…¥ ===
def on_user_submit_text(user_text: str,
                        session: SessionState,
                        role_name: str,
                        llm: LLMClient,
                        debug_on: bool):
    try:
        role = load_role_config(role_name)
        turn = respond(user_text=user_text, state=session, role=role, llm_client=llm)
        chat_pair = [(user_text, turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                # å¦‚æœ classify è¿”å›äº†åˆ†å¸ƒï¼Œä¹Ÿæ˜¾ç¤º
                cls = rd.get("classify")
                if isinstance(cls, dict) and "confidence_map" in cls:
                    rd_pretty = {
                        "rule_hit": rd.get("rule_hit"),
                        "rule_name": rd.get("rule_name"),
                        "best_skill": cls.get("skill"),
                        "best_confidence": cls.get("confidence"),
                        "confidence_map": cls.get("confidence_map"),
                        "_raw_len": len(str(cls.get("_debug", {}).get("raw", "")))
                    }
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd_pretty, ensure_ascii=False, indent=2) + "\n```"
                else:
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        return chat_pair, skill_tag, debug_md, session
    except Exception:
        import traceback; traceback.print_exc()
        return [(user_text, "æŠ±æ­‰ï¼Œå†…éƒ¨å‡ºç°é”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤ã€‚")], "â€”", "â€”", session


# === å›è°ƒï¼šé‡ç½®ä¼šè¯ ===
def on_reset(session: SessionState):
    reset_session(session)
    return session

# è¯­éŸ³å¤„ç†
def on_user_submit_audio(audio_tuple, session: SessionState, role_name: str, llm: LLMClient,
                         debug_on: bool, use_custom_voice: bool, custom_voice: str, custom_speed: float):
    try:
        if audio_tuple is None:
            return [(None, "è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘ã€‚")], "â€”", "â€”", None, session

        sr, audio_np = audio_tuple
        if audio_np.dtype != np.float32:
            audio_np = audio_np.astype(np.float32)
            maxv = max(1.0, float((abs(audio_np).max() or 1.0)))
            audio_np = audio_np / maxv

        role = load_role_config(role_name)
        ov = custom_voice if (use_custom_voice and custom_voice) else None
        ospeed = custom_speed if use_custom_voice else None

        turn = respond_voice(audio_np=audio_np, sample_rate=sr, state=session,
                             role=role, llm_client=llm, override_voice=ov, override_speed=ospeed)

        chat_pair = [("ğŸ¤(è¯­éŸ³)", turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                import json
                debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        audio_path = turn.audio_bytes  # ç°åœ¨æ‰¿è½½çš„æ˜¯æ–‡ä»¶è·¯å¾„
        return chat_pair, skill_tag, debug_md, audio_path, session

    except Exception:
        import traceback
        tb = traceback.format_exc()
        debug_md = "### è¯­éŸ³å¼‚å¸¸\n```\n" + tb[-800:] + "\n```"
        return [("ğŸ¤(è¯­éŸ³)", "æŠ±æ­‰ï¼Œè¯­éŸ³å¤„ç†å¼‚å¸¸ã€‚")], "â€”", debug_md, None, session


# â€œç”Ÿæˆå™¨å¼â€çš„è¯­éŸ³å›è°ƒ
def on_user_submit_audio_stream(audio_tuple,
                                session: SessionState,
                                role_name: str,
                                llm: LLMClient,
                                debug_on: bool,
                                use_custom_voice: bool,
                                custom_voice: str,
                                custom_speed: float):
    """
    ç”Ÿæˆå™¨ï¼šä¸€æ¬¡å½•éŸ³ => å¥çº§å¿«é€Ÿåé¦ˆã€‚
    æ¯æ¬¡ yield æ›´æ–°ï¼šChatbot(ç´¯ç§¯)ã€æŠ€èƒ½æ ‡ç­¾ã€è°ƒè¯•é¢æ¿ã€Audio(å•å¥path)ã€Statusã€Session
    """

    # å…œåº•ï¼šæ²¡éŸ³é¢‘
    if audio_tuple is None:
        # [chatbot, audio_out, status_badge, skill_badge, session_state]
        yield [], None, "â—æœªæ¥æ”¶éŸ³é¢‘", "â€”", session
        return

    # Gradio type="numpy" å½¢æ€ï¼š(sr, np.ndarray[float32, -1..1])
    try:
        sr, audio_np = audio_tuple
    except Exception:
        yield [], None, "â—éŸ³é¢‘æ ¼å¼å¼‚å¸¸", "â€”", session
        return

    if getattr(audio_np, "dtype", None) is not np.float32:
        audio_np = audio_np.astype(np.float32)
        maxv = float(np.max(np.abs(audio_np)) or 1.0)
        audio_np = audio_np / max(1.0, maxv)

    # è§’è‰² + ä¼šè¯çº§éŸ³è‰²è¦†ç›–
    role = load_role_config(role_name)
    if use_custom_voice:
        tts_pref = getattr(role, "tts", {}) or {}
        if custom_voice:
            tts_pref["voice_type"] = custom_voice
        if custom_speed:
            tts_pref["speed_ratio"] = float(custom_speed)
        setattr(role, "tts", tts_pref)

    # å®¢æˆ·ç«¯
    asr = ASRWsClient()
    tts = TTSClient()

    # UIç«¯ç´¯ç§¯å¯¹è¯
    ui_msgs = []

    # é€å¥ç”Ÿæˆï¼šASR â†’ åˆ‡å¥ â†’ çŸ­ç­” â†’ TTS â†’ yield
    gen = voice_sentence_loop(audio_np=audio_np,
                              sample_rate=sr,
                              state=session,
                              role=role,
                              llm_client=llm,
                              asr_client=asr,
                              tts_client=tts)

    for step in gen:
        # æŠŠ step.chat_add åˆå…¥ Chatbot
        for who, txt in step.get("chat_add", []):
            if who == "user":
                ui_msgs.append((txt, None))
            else:
                ui_msgs.append((None, txt))


        # é€æ¬¡åˆ·æ–°ï¼šChatbotã€Audio(å•å¥è·¯å¾„)ã€çŠ¶æ€å¾½æ ‡æ–‡æœ¬ã€æŠ€èƒ½å¾½æ ‡æ–‡æœ¬ã€Session
        skill_txt = step.get("skill_label", "â€”")  # è‹¥è¿˜æ²¡æ¥ classifyï¼Œå¯å…ˆè¿”å› â€œâ€”â€
        yield ui_msgs, step.get("audio_path"), step.get("status", ""), skill_txt, session


def _toggle_drawer(vis: bool):
    return gr.update(visible=not vis)
    
def _load_voices():
    try:
        tts = TTSClient()
        items = tts.list_voices()
        labels, mapping = [], {}
        for it in items:
            vt = it.get("voice_type") or ""
            name = it.get("voice_name") or vt
            cat = it.get("category", "")
            label = f"{name} ({vt})" if name else vt
            if cat:
                label = f"{label} Â· {cat}"
            labels.append(label); mapping[label] = vt
        default_value = labels[0] if labels else None
        # ä¸€æ¬¡æ›´æ–° choices ä¸é»˜è®¤å€¼ï¼Œé¿å…â€œvalue ä¸åœ¨ choices ä¸­â€çš„æŠ¥é”™
        return gr.update(choices=labels, value=default_value), mapping
    except Exception:
        return gr.update(choices=[], value=None), {}

def _label_to_voice(label: str, mapping: dict):
    return mapping.get(label or "", "")

def _on_reset(session: SessionState):
    reset_session(session)
    # ä¾æ¬¡è¿”å›ï¼šchatbot ç©ºåˆ—è¡¨ã€status æ–‡æ¡ˆã€skill æ–‡æ¡ˆã€audio åœæ­¢ã€session
    return [], "å‡†å¤‡å°±ç»ª", "â€”", None, session


CSS_PATH = os.path.join(os.path.dirname(__file__), "assets", "ui.css")
CUSTOM_CSS = open(CSS_PATH, "r", encoding="utf-8").read() if os.path.exists(CSS_PATH) else ""
THEME = gr.themes.Soft(primary_hue="blue", secondary_hue="cyan")  # ä¸­æ€§ä¸å‹å­—

# === ç»„è£… UI ===
def build_ui():
    with gr.Blocks(title="Voicery Â· æ€è¾¨è®­ç»ƒè¥", theme=THEME, css=CUSTOM_CSS) as demo:
        # é¡¶éƒ¨ï¼šå·¦æ ‡é¢˜ + å³ä¸Šâ€œâš™ï¸é«˜çº§è®¾ç½®â€
        with gr.Row(elem_id="header_bar"):
            with gr.Column(scale=5):
                gr.Markdown("<div id='header_title'>ğŸª„ Voicery </div>"
                            "<div id='header_sub'>è§’è‰²æ‰®æ¼” Â· å¥çº§å¿«é€Ÿåé¦ˆ Â· ç§‘æŠ€æ„Ÿ UI</div>")
            with gr.Column(scale=1):
                settings_btn = gr.Button("âš™ï¸ é«˜çº§è®¾ç½®", variant="secondary")

        # å…¨å±€çŠ¶æ€ï¼šä¼šè¯ + LLM å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–åœ¨ Gradio çš„ State é‡Œï¼‰
        session_state = gr.State(SessionState(session_id=str(uuid.uuid4())))
        llm_client = gr.State(LLMClient())   # ä½¿ç”¨ .env/settings.py é…å¥½çš„ API/æ¨¡å‹
        drawer_visible = gr.State(False)

        with gr.Row():
            role_dd = gr.Dropdown(choices=list(ROLES_CACHE.keys()),
                      value=list(ROLES_CACHE.keys())[0],
                      label="é€‰æ‹©è§’è‰²")
            reset_btn = gr.Button("é‡ç½®ä¼šè¯", variant="secondary")

        voices_map = gr.State({})

        # ä¸­é—´ä¸»ä½“ï¼šå·¦â€œèŠå¤©æ¡†ï¼ˆå«è§’æ ‡ï¼‰â€ + å³â€œæŠ½å±‰â€ï¼ˆé»˜è®¤éšè—ï¼‰
        with gr.Row():
            with gr.Column(scale=4):
                with gr.Group(elem_id="chatwrap"):
                    chatbot = gr.Chatbot(label=None, height=520, elem_id="chatbox")
                    status_badge = gr.Markdown("å‡†å¤‡å°±ç»ª", elem_classes=["badge"], elem_id="status_badge")
                    skill_badge  = gr.Markdown("â€”", elem_classes=["badge"], elem_id="skill_badge")
            with gr.Column(scale=2, visible=False, elem_id="drawer") as drawer:
                with gr.Group(elem_id="right_card"):
                    gr.Markdown("#### é¢æ¿")
                    # è°ƒè¯•å¼€å…³ & ä¿¡æ¯
                    debug_ck = gr.Checkbox(label="è°ƒè¯•æ¨¡å¼", value=False)
                    debug_panel = gr.Markdown(value="ï¼ˆè°ƒè¯•è¾“å‡ºæ˜¾ç¤ºåœ¨æ­¤ï¼‰")

                with gr.Group(elem_id="right_card"):
                    gr.Markdown("#### è¯­éŸ³å‚æ•°")
                    use_custom_voice = gr.Checkbox(label="å¯ç”¨è‡ªå®šä¹‰éŸ³è‰²", value=True)
                    voice_label_dd   = voice_label_dd   = gr.Dropdown(
                        label="éŸ³è‰²ï¼ˆä»å®˜æ–¹åˆ—è¡¨åŠ è½½ï¼‰",
                        choices=[], value=None, allow_custom_value=True
                    )
                    custom_voice     = gr.Textbox(label="voice_typeï¼ˆéšè—ç»‘å®šï¼‰", visible=False)
                    custom_speed     = gr.Slider(0.7, 1.3, value=0.95, step=0.01, label="speed_ratioï¼ˆ0.7~1.3ï¼‰")


        # åº•éƒ¨ç»Ÿä¸€è¾“å…¥åŒº
        with gr.Row(elem_id="input_row"):
            txt_in   = gr.Textbox(label=None, show_label=False,
                                  placeholder="è¾“å…¥æ–‡å­—ï¼Œæˆ–ç‚¹å³ä¾§ ğŸ™ï¸ è¯´è¯â€¦", lines=3)
            mic      = gr.Audio(sources=["microphone"], type="numpy", label=None, show_label=False, visible=False)
            mic_btn  = gr.Button("ğŸ™ï¸ è¯­éŸ³", variant="secondary", elem_id="mic_btn")
            send_btn = gr.Button("å‘é€", variant="primary")
            stop_btn = gr.Button("â¹ åœæ­¢æ’­æ”¾", variant="secondary")

        # éšå½¢æ’­æ”¾å™¨ï¼šæ¯å¥äº§å‡ºç›´æ¥ autoplay
        audio_out = gr.Audio(label=None, type="filepath", autoplay=True, visible=False)

        gr.Markdown("<div style='opacity:.6'>âš ï¸ Voicery å¯èƒ½å‡ºé”™, è¯·æ ¸éªŒå…³é”®ä¿¡æ¯</div>")

        # é«˜çº§è®¾ç½®ï¼šå¼€/åˆ + æ‹‰å–éŸ³è‰²
        def _toggle_drawer_state(v: bool):
            return not v
        def _apply_drawer(v: bool):
            return gr.update(visible=v)

        settings_btn.click(
            _toggle_drawer_state, inputs=[drawer_visible], outputs=[drawer_visible]
        ).then(
            _apply_drawer, inputs=[drawer_visible], outputs=[drawer]
        ).then(
            _load_voices, inputs=None, outputs=[voice_label_dd, voices_map]
        )

        # é€‰æ‹©æŸéŸ³è‰² -> å†™å…¥éšè—çš„ custom_voiceï¼ˆè°ƒç”¨é“¾ä¿æŒä¸å˜ï¼‰
        voice_label_dd.change(_label_to_voice, inputs=[voice_label_dd, voices_map], outputs=[custom_voice])

        def _toggle_mic(vis: bool):
            return gr.update(visible=not vis)

        mic_btn.click(_toggle_mic, inputs=[mic], outputs=[mic])

        mic.change(
            fn=on_user_submit_audio_stream,
            inputs=[mic, session_state, role_dd, llm_client, debug_ck, use_custom_voice, custom_voice, custom_speed],
            outputs=[chatbot, audio_out, status_badge, skill_badge, session_state]   # â† æ³¨æ„ï¼šè¾“å‡ºç›®æ ‡å˜äº†
        )

        # æ–‡æœ¬äº‹ä»¶
        send_btn.click(
            fn=on_user_submit_text,
            inputs=[txt_in, session_state, role_dd, llm_client, debug_ck],
            outputs=[chatbot, skill_badge, debug_panel, session_state]   # æŠ€èƒ½å¾½æ ‡=skill_badge
        ).then(lambda: "", None, txt_in)# å‘é€åæ¸…ç©ºè¾“å…¥æ¡†
        

        # è¯­éŸ³äº‹ä»¶
        def _stop_play():
            return None, "â¹ å·²åœæ­¢æ’­æ”¾"

        stop_btn.click(_stop_play, outputs=[audio_out, status_badge])

    demo.launch(show_api=False)   # â€œé€šè¿‡ API ä½¿ç”¨â€ä¸æ˜¾ç¤ºï¼›å…¶å®ƒé€šè¿‡ CSS å·²éšè—

if __name__ == "__main__":
    build_ui()
