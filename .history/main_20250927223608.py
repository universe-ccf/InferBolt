# main.py
from __future__ import annotations
import os, io, uuid
import gradio as gr
from clients.llm_client import LLMClient
from core.state import SessionState, reset_session
from core.types import RoleConfig
from core.roles import load_all_roles
import json
import numpy as np
from core.pipeline import respond, respond_voice
from core.pipeline import voice_sentence_loop, respond_short  
from clients.asr_ws_client import ASRWsClient                          
from clients.tts_client import TTSClient                                


SKILL_LABELS = {
    "steelman": "å¼ºåŒ–è®ºè¯",
    "x_exam": "äº¤å‰è´¨è¯¢",
    "counterfactual": "åäº‹å®æŒ‘æˆ˜",
}


# === åŠ è½½è§’è‰²é…ç½®===
ROLES_CACHE = load_all_roles()

def load_role_config(name: str) -> RoleConfig:
    return ROLES_CACHE.get(name, list(ROLES_CACHE.values())[0])

# === å›è°ƒï¼šæ–‡æœ¬è¾“å…¥ ===
def on_user_submit_text(user_text: str,
                        session: SessionState,
                        role_name: str,
                        llm: LLMClient,
                        debug_on: bool):
    try:
        role = load_role_config(role_name)
        turn = respond(user_text=user_text, state=session, role=role, llm_client=llm)
        chat_pair = [(user_text, turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                # å¦‚æœ classify è¿”å›äº†åˆ†å¸ƒï¼Œä¹Ÿæ˜¾ç¤º
                cls = rd.get("classify")
                if isinstance(cls, dict) and "confidence_map" in cls:
                    rd_pretty = {
                        "rule_hit": rd.get("rule_hit"),
                        "rule_name": rd.get("rule_name"),
                        "best_skill": cls.get("skill"),
                        "best_confidence": cls.get("confidence"),
                        "confidence_map": cls.get("confidence_map"),
                        "_raw_len": len(str(cls.get("_debug", {}).get("raw", "")))
                    }
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd_pretty, ensure_ascii=False, indent=2) + "\n```"
                else:
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        return chat_pair, skill_tag, debug_md, session
    except Exception:
        import traceback; traceback.print_exc()
        return [(user_text, "æŠ±æ­‰ï¼Œå†…éƒ¨å‡ºç°é”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤ã€‚")], "â€”", "â€”", session


# === å›è°ƒï¼šé‡ç½®ä¼šè¯ ===
def on_reset(session: SessionState):
    reset_session(session)
    return session

# è¯­éŸ³å¤„ç†
def on_user_submit_audio(audio_tuple, session: SessionState, role_name: str, llm: LLMClient,
                         debug_on: bool, use_custom_voice: bool, custom_voice: str, custom_speed: float):
    try:
        if audio_tuple is None:
            return [(None, "è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘ã€‚")], "â€”", "â€”", None, session

        sr, audio_np = audio_tuple
        if audio_np.dtype != np.float32:
            audio_np = audio_np.astype(np.float32)
            maxv = max(1.0, float((abs(audio_np).max() or 1.0)))
            audio_np = audio_np / maxv

        role = load_role_config(role_name)
        ov = custom_voice if (use_custom_voice and custom_voice) else None
        ospeed = custom_speed if use_custom_voice else None

        turn = respond_voice(audio_np=audio_np, sample_rate=sr, state=session,
                             role=role, llm_client=llm, override_voice=ov, override_speed=ospeed)

        chat_pair = [("ğŸ¤(è¯­éŸ³)", turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                import json
                debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        audio_path = turn.audio_bytes  # ç°åœ¨æ‰¿è½½çš„æ˜¯æ–‡ä»¶è·¯å¾„
        return chat_pair, skill_tag, debug_md, audio_path, session

    except Exception:
        import traceback
        tb = traceback.format_exc()
        debug_md = "### è¯­éŸ³å¼‚å¸¸\n```\n" + tb[-800:] + "\n```"
        return [("ğŸ¤(è¯­éŸ³)", "æŠ±æ­‰ï¼Œè¯­éŸ³å¤„ç†å¼‚å¸¸ã€‚")], "â€”", debug_md, None, session


# â€œç”Ÿæˆå™¨å¼â€çš„è¯­éŸ³å›è°ƒ
def on_user_submit_audio_stream(audio_tuple,
                                session: SessionState,
                                role_name: str,
                                llm: LLMClient,
                                debug_on: bool,
                                use_custom_voice: bool,
                                custom_voice: str,
                                custom_speed: float):
    """
    ç”Ÿæˆå™¨ï¼šä¸€æ¬¡å½•éŸ³ => å¥çº§å¿«é€Ÿåé¦ˆã€‚
    æ¯æ¬¡ yield æ›´æ–°ï¼šChatbot(ç´¯ç§¯)ã€æŠ€èƒ½æ ‡ç­¾ã€è°ƒè¯•é¢æ¿ã€Audio(å•å¥path)ã€Statusã€Session
    """

    # å…œåº•ï¼šæ²¡éŸ³é¢‘
    if audio_tuple is None:
        yield [(None, "è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘ã€‚")], "â€”", "â€”", None, "â—æœªæ¥æ”¶éŸ³é¢‘", session
        return

    # Gradio type="numpy" å½¢æ€ï¼š(sr, np.ndarray[float32, -1..1])
    try:
        sr, audio_np = audio_tuple
    except Exception:
        # å¦‚æœä½ æ”¹æˆ filepath æ¨¡å¼ï¼Œè¿™é‡Œè¦å…ˆè¯»æˆ npï¼›ç›®å‰æˆ‘ä»¬ä»æŒ‰ numpy èµ°
        yield [(None, "éŸ³é¢‘æ ¼å¼å¼‚å¸¸ã€‚")], "â€”", "â€”", None, "â—éŸ³é¢‘æ ¼å¼å¼‚å¸¸", session
        return

    if getattr(audio_np, "dtype", None) is not np.float32:
        audio_np = audio_np.astype(np.float32)
        maxv = float(np.max(np.abs(audio_np)) or 1.0)
        audio_np = audio_np / max(1.0, maxv)

    # è§’è‰² + ä¼šè¯çº§éŸ³è‰²è¦†ç›–
    role = load_role_config(role_name)
    if use_custom_voice:
        tts_pref = getattr(role, "tts", {}) or {}
        if custom_voice:
            tts_pref["voice_type"] = custom_voice
        if custom_speed:
            tts_pref["speed_ratio"] = float(custom_speed)
        setattr(role, "tts", tts_pref)

    # å®¢æˆ·ç«¯
    asr = ASRWsClient()
    tts = TTSClient()

    # UIç«¯ç´¯ç§¯å¯¹è¯
    ui_msgs = []

    # é€å¥ç”Ÿæˆï¼šASR â†’ åˆ‡å¥ â†’ çŸ­ç­” â†’ TTS â†’ yield
    gen = voice_sentence_loop(audio_np=audio_np,
                              sample_rate=sr,
                              state=session,
                              role=role,
                              llm_client=llm,
                              asr_client=asr,
                              tts_client=tts)

    for step in gen:
        # æŠŠ step.chat_add åˆå…¥ Chatbot
        for who, txt in step.get("chat_add", []):
            if who == "user":
                ui_msgs.append((txt, None))
            else:
                ui_msgs.append((None, txt))

        # é€æ¬¡åˆ·æ–° UIï¼ˆæŠ€èƒ½ä¸è°ƒè¯•é¢æ¿å…ˆä¿æŒâ€œâ€”â€ï¼‰
        yield ui_msgs, "â€”", "â€”", step.get("audio_path"), step.get("status", ""), session


THEME = gr.themes.Soft(primary_hue="violet", secondary_hue="cyan")

CUSTOM_CSS = """
:root { --radius-xl: 22px; }
.gradio-container { background: radial-gradient(1200px 600px at 20% -10%, rgba(120,90,255,.18), transparent),
                               radial-gradient(1000px 500px at 120% 10%, rgba(0,220,255,.10), transparent),
                               #0b0d15; color: #e7e9ef; }
#status_bar { border-radius: 14px; padding: 10px 12px; background: rgba(255,255,255,0.04);
              border: 1px solid rgba(255,255,255,0.06); backdrop-filter: blur(8px); }
button, .gr-button { border-radius: 16px !important; }
.gradio-chatbot { border-radius: 18px !important; background: rgba(255,255,255,0.03) !important;
                  border: 1px solid rgba(255,255,255,0.06) !important; }
"""


# === ç»„è£… UI ===
def build_ui():
    with gr.Blocks(title="Voicery Â· æ€è¾¨è®­ç»ƒè¥", theme=THEME, css=CUSTOM_CSS) as demo:
        gr.Markdown("<h2 style='margin-bottom:6px'>ğŸª„ Voice </h2><div style='opacity:.7'>è§’è‰²æ‰®æ¼” Â· å¥çº§å¿«é€Ÿåé¦ˆ Â· ç§‘æŠ€æ„ŸUI</div>")

        # å…¨å±€çŠ¶æ€ï¼šä¼šè¯ + LLM å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–åœ¨ Gradio çš„ State é‡Œï¼‰
        session_state = gr.State(SessionState(session_id=str(uuid.uuid4())))
        llm_client = gr.State(LLMClient())   # ä½¿ç”¨ .env/settings.py é…å¥½çš„ API/æ¨¡å‹

        with gr.Row():
            role_dd = gr.Dropdown(choices=list(ROLES_CACHE.keys()),
                      value=list(ROLES_CACHE.keys())[0],
                      label="é€‰æ‹©è§’è‰²")
            debug_ck = gr.Checkbox(label="è°ƒè¯•æ¨¡å¼", value=True)
            reset_btn = gr.Button("é‡ç½®ä¼šè¯", variant="secondary")

        chatbot = gr.Chatbot(label="å¯¹è¯åŒº", height=350)

        status = gr.Markdown("å‡†å¤‡å°±ç»ª", elem_id="status_bar")

        gr.Markdown("<div style='opacity:.6'>âš ï¸ Voicery å¯èƒ½å‡ºé”™, è¯·æ ¸éªŒå…³é”®ä¿¡æ¯</div>")

        # æŠ€èƒ½çŠ¶æ€æŒ‡ç¤ºç»„ä»¶
        skill_info = gr.Markdown(value="â€”", label="æŠ€èƒ½çŠ¶æ€")

        debug_panel = gr.Markdown(value="â€”", label="è°ƒè¯•ä¿¡æ¯")

        with gr.Tab("æ–‡æœ¬å¯¹è¯"):
            with gr.Row():
                txt_in = gr.Textbox(label="è¾“å…¥ä½ çš„è¯", 
                                    placeholder="ä¾‹ï¼šå¼ºåŒ–è®ºè¯ / äº¤å‰è´¨è¯¢ / åäº‹å®æŒ‘æˆ˜", 
                                    lines=2)
                send_btn = gr.Button("å‘é€", variant="primary")

        with gr.Tab("è¯­éŸ³å¯¹è¯"):
            with gr.Row():
                mic = gr.Audio(sources=["microphone", "upload"], type="numpy", label="å½•éŸ³æˆ–ä¸Šä¼ ï¼ˆå•å£°é“ï¼‰")
                send_v = gr.Button("å‘é€è¯­éŸ³", variant="primary")
                audio_out = gr.Audio(label="è¯­éŸ³å›å¤ï¼ˆå¥çº§ï¼‰", type="filepath", autoplay=True)

            # é«˜çº§è®¾ç½®ï¼ˆä¼šè¯è¦†ç›–ï¼‰
            with gr.Accordion("é«˜çº§è®¾ç½®ï¼ˆä¼šè¯è¦†ç›–è§’è‰²éŸ³è‰²ï¼‰", open=False):
                use_custom_voice = gr.Checkbox(label="ä½¿ç”¨è‡ªå®šä¹‰éŸ³è‰²", value=False)
                custom_voice = gr.Textbox(label="voice_typeï¼ˆç•™ç©ºåˆ™ç”¨è§’è‰²é»˜è®¤ï¼‰", placeholder="ä¾‹å¦‚ï¼šqiniu_zh_male_cxkjns")
                custom_speed = gr.Slider(0.6, 1.3, value=0.92, step=0.02, label="speed_ratioï¼ˆ0.6~1.3ï¼‰")


        # æ–‡æœ¬äº‹ä»¶
        send_btn.click(
            fn=on_user_submit_text,
            inputs=[txt_in, session_state, role_dd, llm_client, debug_ck],
            outputs=[chatbot, skill_info, debug_panel, session_state]
        ).then(  # å‘é€åæ¸…ç©ºè¾“å…¥æ¡†
            lambda: "", None, txt_in
        )

        # è¯­éŸ³äº‹ä»¶
        send_v.click(
            fn=on_user_submit_audio_stream,
            inputs=[mic, session_state, role_dd, llm_client, debug_ck, use_custom_voice, custom_voice, custom_speed],
            outputs=[chatbot, skill_info, debug_panel, audio_out, status, session_state]
        )

        reset_btn.click(
            fn=on_reset,
            inputs=[session_state],
            outputs=[session_state]
        ).then(
            lambda: None, None, chatbot
        ).then(
            lambda: "â€”", None, skill_info  # é‡ç½®æŠ€èƒ½æŒ‡ç¤º
        ).then(
            lambda: "â€”", None, debug_panel
        ).then(
            lambda: None, None, audio_out
        ).then(
            lambda: "", None, txt_in
        )

    demo.launch()

if __name__ == "__main__":
    build_ui()
