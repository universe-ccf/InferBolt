# Voicery · 架构设计文档

> 目标：一个可搜索与对话的“角色扮演 + 语音”应用。支持文本与语音双链路、多轮记忆、技能路由（思辨类 & 关怀类 & 教学类），并与七牛云端大模型兼容接口对接（LLM / ASR / TTS）。

---

## 1. 总体架构



**数据流：**

- **文本链路**：UI → `respond()` →（路由）→ 普通对话或技能 → LLM → 更新 `SessionState.messages` → UI显示（支持“整段”或“真·流式”）。
- **语音链路**：UI录音 → `respond_voice()`：
  1. `ASRWsClient.transcribe()`（WS帧协议 + gzip + JSON）  
  2. 得到 `user_text` 后复用 `respond()` → LLM  
  3. `TTSClient.synthesize()` → 生成 `wav` → 文件缓存 → 返回路径  
  4. UI 播放（当前版本：**HTML自动播放**；也保留回退：Gradio `gr.Audio`）。

---

## 2. 配置与常量（`config/settings.py`）

- **LLM**：`LLM_MODEL`, `LLM_TEMPERATURE`, `MAX_ROUNDS`, `MAX_TOKENS_RESPONSE`, `API_KEY`, `BASE_URL`
- **ASR/TTS**：`ASR_TRANSPORT=ws`, `ASR_WS_URL`, `TTS_VOICE`, `TTS_ENCODING="wav"`, `TTS_SPEED`
- **超时/重试**：`CONNECT_TIMEOUT`, `READ_TIMEOUT`, `REQUEST_TIMEOUT=(conn,read)`, `HTTP_MAX_RETRIES`, `HTTP_BACKOFF_SEC`
- **语音音频规范化/静音裁剪**：`TTS_SILENCE_DBFS`, `TTS_RMS_WIN_MS`, `TTS_TRIM_PAD_MS`, `TTS_TARGET_SR`
- **技能路由**：`SKILL_CANDIDATES`、`SKILL_DESCRIPTIONS`、`INTENT_CONF_THRESHOLD`
- **缓存**：`ENABLE_SPEECH_CACHE`, `CACHE_TTS_DIR`, `CACHE_ASR_DIR`
- **日志**：`ENABLE_LOGGING`, `LOG_PATH`, `DEBUG`
- **文本/语音模式细节**：`TEXT_STREAMING`、`MAX_REPLY_CHARS_VOICE`, `SENTENCE_SILENCE_MS`

> **说明**：`MAX_ROUNDS` 决定历史消息的截断窗口（见 §6）。

---

## 3. Core 模块

### 3.1 类型与状态（`core/types.py` & `core/state.py`）

- `Message(role, content, meta={})`
- `TurnResult(reply_text, skill, data, audio_bytes)`
- `SkillResult(name, display_tag, reply_text, data)`
- `RoleConfig(name, style, persona, catchphrases, taboos, format_prefs, mission, tts)`
- `SessionState(session_id, messages=[], last_skill=None)`
- 工具函数：
  - `append_turn(state, user_msg, assistant_msg, max_rounds)`
  - `get_recent_messages(state, max_rounds)`
  - `reset_session(state)`

### 3.2 路由（`core/dispatcher.py`）

- 规则优先（关键词 → skill）
- 未命中：调用 `llm_client.classify(text)`  
  - 返回 `confidence_map`；代码端 `argmax` + 阈值 `INTENT_CONF_THRESHOLD`
- 未达阈值或 `none`：走普通对话

### 3.3 管线（`core/pipeline.py`）

- `build_system_prompt(role)`
- `assemble_messages(system, history, user_text)`
- `run_skill(name, user_text, role, history, llm_client)`
- `respond(user_text, state, role, llm_client)`
- `respond_voice(audio_np, sample_rate, ...)`
- `respond_short(...)`
- `voice_sentence_loop(...)`

---

## 4. Clients

### 4.1 LLM（`clients/llm_client.py`）

- `complete(messages, max_tokens=..., stream=False) -> str`
- `complete_chunks(messages, max_tokens=...) -> Iterable[str]`
- `classify(text) -> dict`

### 4.2 ASR（`clients/asr_ws_client.py`）

- WebSocket 协议：配置帧 → 音频帧 → 结束帧
- 返回 `ASRResult(text, confidence, meta)`

### 4.3 TTS（`clients/tts_client.py`）

- POST `/voice/tts`，返回 base64 音频  
- 处理：RMS → 单声道 → 静音裁剪 → 采样率一致  
- 缓存机制（sha256）  
- 返回 `TTSResult(audio_path, sample_rate, meta)`

---

## 5. Skills（策略层）

- **Socrates**：`steelman`、`x_exam`、`counterfactual`
- **Luma**：`luma_story`、`luma_reframe`、`luma_roleplay`
- **Aris**：`aris_reverse`、`aris_practice`、`aris_bimap`

统一签名：

```python
def run(user_text: str, role: RoleConfig, history: List[Message], llm_client) -> SkillResult

```

---


# 6. UI（main.py & assets/ui.css）

## 6.1 主要组件

- 状态与依赖：

  - session_state = gr.State(SessionState(...))

  - llm_client = gr.State(LLMClient())

  - voices_map = gr.State({})（TTS音色映射）

- 输入区：Textbox（文本），Audio（麦克风）

- 输出区：Chatbot、状态徽标（Markdown）、技能徽标（Markdown）

- 音频播放：当前配置为 gr.HTML（自动播放 <audio autoplay>）；可回退为 gr.Audio(type="filepath", autoplay=True) 并显式显示

- 抽屉：调试开关、TTS音色选择、速度滑杆

## 6.2 回调（文本）

- on_user_submit_text_stream(user_text, chatbot_hist, session, role, llm, debug_on)

  - 真·流式：用 llm.complete_chunks() 逐片更新最后一条消息

  - 完成后 append_turn(...) 写回 SessionState.messages

- 非流式版本 on_user_submit_text 亦保留

## 6.3 回调（语音）

- on_user_submit_audio_stream(audio_tuple, chatbot_cur, session, role, llm, ...)

  - 生成器：voice_sentence_loop(...) 逐句 yield

  - 将 step.chat_add 合并到 ui_msgs（防止覆盖历史）

  - 若使用 HTML 播放：拼出 <audio src="... " autoplay playsinline style="display:none"></audio>

  - 若回退 Gradio 播放：将输出改回 gr.Audio 组件并传入 filepath

- **“重新录制”**按钮行为（推荐）：只清麦克风控件值，不清对话历史

  - re_record_btn.click(lambda: None, outputs=[mic])

## 6.4 CSS（assets/ui.css）

- 玻璃态卡片、徽标（badge）样式

- 如果出现遮挡：

  - 可把状态徽标迁移到输入区右侧（UI层已预留：将 status_badge/skill_badge 放到 input_row 某列内）

  - 或调整 position:absolute → 放入布局流（position:static）并在 main.py 中改挂载位置

## 7. 日志与可观测性（utils/logging.py）

- 关键事件（示例）：

- chat_turn（路径、技能、回复长度、路由调试）

- voice_turn（各阶段耗时、ASR/TTS 元信息）

- asr_ws_open/cfg_ack/partial/done/error

- tts_request/response/wav_info/trim_applied/save_done/error

- voice_sentence_loop_done

- 语音失败短路：voice_asr_failed_shortcircuit

日志落地：logs/app.jsonl（每行一条 JSON）

## 8. 会话窗口与性能

- 历史窗口：append_turn() 只保留最近 2 * MAX_ROUNDS 条消息（user+assistant 计 2 条）。

- 超过上限：自动截尾，防止 prompt 过长导致 响应变慢 / 费用上升 / 服务器拒绝。

- 建议：文本模式 MAX_ROUNDS 8~12；语音模式可更小（3~6），配合短句策略。

- 流式：文本采用 complete_chunks 直接刷 UI → 首字符时间更短。

- TTS：长文本合成成本高，代码侧对 TTS 文本长度做截断（如 300 字）+ 句级拆分（语音快速模式）。


## 工作量
### 产品/策划（PM）

- 用户画像与用户故事；角色设定（Socrates / Luma / Aris）

- 技能清单与优先级；对话 UX（文本/语音模式）

### 后端（BE）

- clients/* 对接与健壮性（重试/超时/SSE解析）

- core/* 管线、路由、状态与日志

- 缓存（TTS/ASR）、音频处理（PCM/WAV）

### 前端（FE-UI/Gradio）

- 组件布局、徽标位置与状态提示

- 文本真·流式刷新、音频自动播/回退策略

- 录音控件的“只清音频不清历史”交互

### 算法/NLP（Skill Author）

- 提示词工程；技能模板结构化输出

- 分类器提示（意图分类/技能选择）

### 测试（QA）

- 文本/语音回归；极端网络/时延

- 长文本截断/多轮记忆窗口

- 编解码/乱码/SSE代理场景

### 运维（DevOps）

- .env/密钥管理；日志/监控
