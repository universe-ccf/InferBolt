# main.py
from __future__ import annotations
import os, io, uuid
import gradio as gr
from clients.llm_client import LLMClient
from core.pipeline import respond
from core.state import SessionState, reset_session
from core.types import RoleConfig
from core.roles import load_all_roles
import json
import numpy as np
from core.pipeline import respond, respond_voice
from config import settings


SKILL_LABELS = {
    "steelman": "å¼ºåŒ–è®ºè¯",
    "x_exam": "äº¤å‰è´¨è¯¢",
    "counterfactual": "åäº‹å®æŒ‘æˆ˜",
}


# === åŠ è½½è§’è‰²é…ç½®===
ROLES_CACHE = load_all_roles()

def load_role_config(name: str) -> RoleConfig:
    return ROLES_CACHE.get(name, list(ROLES_CACHE.values())[0])

# === å›è°ƒï¼šæ–‡æœ¬è¾“å…¥ ===
def on_user_submit_text(user_text: str,
                        session: SessionState,
                        role_name: str,
                        llm: LLMClient,
                        debug_on: bool):
    try:
        role = load_role_config(role_name)
        turn = respond(user_text=user_text, state=session, role=role, llm_client=llm)
        chat_pair = [(user_text, turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                # å¦‚æœ classify è¿”å›äº†åˆ†å¸ƒï¼Œä¹Ÿæ˜¾ç¤º
                cls = rd.get("classify")
                if isinstance(cls, dict) and "confidence_map" in cls:
                    rd_pretty = {
                        "rule_hit": rd.get("rule_hit"),
                        "rule_name": rd.get("rule_name"),
                        "best_skill": cls.get("skill"),
                        "best_confidence": cls.get("confidence"),
                        "confidence_map": cls.get("confidence_map"),
                        "_raw_len": len(str(cls.get("_debug", {}).get("raw", "")))
                    }
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd_pretty, ensure_ascii=False, indent=2) + "\n```"
                else:
                    debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        return chat_pair, skill_tag, debug_md, session
    except Exception:
        import traceback; traceback.print_exc()
        return [(user_text, "æŠ±æ­‰ï¼Œå†…éƒ¨å‡ºç°é”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤ã€‚")], "â€”", "â€”", session


# === å›è°ƒï¼šé‡ç½®ä¼šè¯ ===
def on_reset(session: SessionState):
    reset_session(session)
    return session

# è¯­éŸ³å¤„ç†
def on_user_submit_audio(audio_tuple, session: SessionState, role_name: str, llm: LLMClient,
                         debug_on: bool, use_custom_voice: bool, custom_voice: str, custom_speed: float):
    try:
        if audio_tuple is None:
            return [(None, "è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘ã€‚")], "â€”", "â€”", None, session

        sr, audio_np = audio_tuple
        if audio_np.dtype != np.float32:
            audio_np = audio_np.astype(np.float32)
            maxv = max(1.0, float((abs(audio_np).max() or 1.0)))
            audio_np = audio_np / maxv

        role = load_role_config(role_name)
        ov = custom_voice if (use_custom_voice and custom_voice) else None
        ospeed = custom_speed if use_custom_voice else None

        turn = respond_voice(audio_np=audio_np, sample_rate=sr, state=session,
                             role=role, llm_client=llm, override_voice=ov, override_speed=ospeed)

        chat_pair = [("ğŸ¤(è¯­éŸ³)", turn.reply_text)]
        label = SKILL_LABELS.get(turn.skill) if turn.skill else None
        skill_tag = f"ğŸ§  å·²è§¦å‘ï¼š`{label}`" if label else "â€”"

        debug_md = "â€”"
        if debug_on:
            rd = turn.data.get("route_debug")
            if rd:
                import json
                debug_md = "### è·¯ç”±è°ƒè¯•\n```json\n" + json.dumps(rd, ensure_ascii=False, indent=2) + "\n```"

        audio_path = turn.audio_bytes  # ç°åœ¨æ‰¿è½½çš„æ˜¯æ–‡ä»¶è·¯å¾„
        return chat_pair, skill_tag, debug_md, audio_path, session

    except Exception:
        import traceback
        tb = traceback.format_exc()
        debug_md = "### è¯­éŸ³å¼‚å¸¸\n```\n" + tb[-800:] + "\n```"
        return [("ğŸ¤(è¯­éŸ³)", "æŠ±æ­‰ï¼Œè¯­éŸ³å¤„ç†å¼‚å¸¸ã€‚")], "â€”", debug_md, None, session


# === ç»„è£… UI ===
def build_ui():
    with gr.Blocks(title="AI è§’è‰²æ‰®æ¼” Â· æ€è¾¨è®­ç»ƒè¥(MVP)") as demo:
        gr.Markdown("## AI è§’è‰²æ‰®æ¼”ï¼ˆæ€è¾¨è®­ç»ƒè¥ï¼‰")

        # å…¨å±€çŠ¶æ€ï¼šä¼šè¯ + LLM å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–åœ¨ Gradio çš„ State é‡Œï¼‰
        session_state = gr.State(SessionState(session_id=str(uuid.uuid4())))
        llm_client = gr.State(LLMClient())   # ä½¿ç”¨ .env/settings.py é…å¥½çš„ API/æ¨¡å‹

        with gr.Row():
            role_dd = gr.Dropdown(choices=list(ROLES_CACHE.keys()),
                      value=list(ROLES_CACHE.keys())[0],
                      label="é€‰æ‹©è§’è‰²")
            debug_ck = gr.Checkbox(label="è°ƒè¯•æ¨¡å¼", value=True)
            reset_btn = gr.Button("é‡ç½®ä¼šè¯", variant="secondary")

        chatbot = gr.Chatbot(label="å¯¹è¯åŒº", height=350)

        gr.Markdown("### AIä¹Ÿä¼šçŠ¯é”™ï¼Œè¯·æ£€æŸ¥é‡è¦ä¿¡æ¯ï¼")

        # æŠ€èƒ½çŠ¶æ€æŒ‡ç¤ºç»„ä»¶
        skill_info = gr.Markdown(value="â€”", label="æŠ€èƒ½çŠ¶æ€")

        debug_panel = gr.Markdown(value="â€”", label="è°ƒè¯•ä¿¡æ¯")

        with gr.Tab("æ–‡æœ¬å¯¹è¯"):
            with gr.Row():
                txt_in = gr.Textbox(label="è¾“å…¥ä½ çš„è¯", 
                                    placeholder="ä¾‹ï¼šå¼ºåŒ–è®ºè¯ / äº¤å‰è´¨è¯¢ / åäº‹å®æŒ‘æˆ˜", 
                                    lines=2)
                send_btn = gr.Button("å‘é€", variant="primary")

        with gr.Tab("è¯­éŸ³å¯¹è¯"):
            with gr.Row():
                mic = gr.Audio(sources=["microphone", "upload"], type="numpy", label="å½•éŸ³æˆ–ä¸Šä¼ ï¼ˆå•å£°é“ï¼‰")
                send_v = gr.Button("å‘é€è¯­éŸ³", variant="primary")
                audio_out = gr.Audio(label="è¯­éŸ³å›å¤ï¼ˆTTSï¼‰", type="filepath")

            # é«˜çº§è®¾ç½®ï¼ˆä¼šè¯è¦†ç›–ï¼‰
            with gr.Accordion("é«˜çº§è®¾ç½®ï¼ˆä¼šè¯è¦†ç›–è§’è‰²éŸ³è‰²ï¼‰", open=False):
                use_custom_voice = gr.Checkbox(label="ä½¿ç”¨è‡ªå®šä¹‰éŸ³è‰²", value=False)
                custom_voice = gr.Textbox(label="voice_typeï¼ˆç•™ç©ºåˆ™ç”¨è§’è‰²é»˜è®¤ï¼‰", placeholder="ä¾‹å¦‚ï¼šqiniu_zh_male_cxkjns")
                custom_speed = gr.Slider(0.6, 1.3, value=0.92, step=0.02, label="speed_ratioï¼ˆ0.6~1.3ï¼‰")


        # æ–‡æœ¬äº‹ä»¶
        send_btn.click(
            fn=on_user_submit_text,
            inputs=[txt_in, session_state, role_dd, llm_client, debug_ck],
            outputs=[chatbot, skill_info, debug_panel, session_state]
        ).then(  # å‘é€åæ¸…ç©ºè¾“å…¥æ¡†
            lambda: "", None, txt_in
        )

        # è¯­éŸ³äº‹ä»¶
        send_v.click(
            fn=on_user_submit_audio,
            inputs=[mic, session_state, role_dd, llm_client, debug_ck, use_custom_voice, custom_voice, custom_speed],
            outputs=[chatbot, skill_info, debug_panel, audio_out, session_state]
        )

        reset_btn.click(
            fn=on_reset,
            inputs=[session_state],
            outputs=[session_state]
        ).then(
            lambda: None, None, chatbot
        ).then(
            lambda: "â€”", None, skill_info  # é‡ç½®æŠ€èƒ½æŒ‡ç¤º
        ).then(
            lambda: "â€”", None, debug_panel
        ).then(
            lambda: None, None, audio_out
        ).then(
            lambda: "", None, txt_in
        )

    demo.launch()

if __name__ == "__main__":
    build_ui()
