# core/pipeline.py
from __future__ import annotations
from typing import Generator, List, Dict, Optional, Any
from .types import Message, RoleConfig, TurnResult, SkillResult
from .state import SessionState, get_recent_messages, append_turn
from .dispatcher import route
from config import settings
from skills import steelman as skill_steelman
from skills import x_exam as skill_x_exam
from skills import counterfactual as skill_cf
from skills import luma_story, luma_reframe, luma_roleplay
from skills import aris_reverse, aris_practice, aris_bimap
from utils.logging import write_log
import time
from clients.asr_client import ASRClient
from clients.tts_client import TTSClient
from clients.asr_ws_client import ASRWsClient
from utils.textseg import split_for_tts
import os


# æ ¹æ®è§’è‰²é…ç½®ç”Ÿæˆsystem promptï¼ˆå£å»ã€ç¦åŒºã€æ ¼å¼åå¥½ï¼‰
def build_system_prompt(role: RoleConfig) -> str:
    parts = [f"ä½ ç°åœ¨æ‰®æ¼”ï¼š{role.name}ã€‚é£æ ¼ï¼š{role.style}ã€‚"]
    if role.mission:
        parts.append(f"ä½¿å‘½ï¼š{role.mission}ã€‚")
    if role.persona:
        parts.append("äººè®¾è¦ç‚¹ï¼š" + "ï¼›".join(role.persona))
    if role.taboos:
        parts.append("é¿å…è¾“å‡ºï¼š" + "ï¼›".join(role.taboos))
    if role.format_prefs:
        if role.format_prefs.get("bullets", False):
            parts.append("å¦‚å¯ï¼Œé‡‡ç”¨åˆ†ç‚¹è¡¨è¾¾ã€‚")
        if role.format_prefs.get("max_words"):
            parts.append(f"å°½é‡ä¸è¶…è¿‡ {role.format_prefs['max_words']} å­—ã€‚")
    parts.append("è¯·ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚")
    return " ".join(parts)



# æŠŠsystem + å†å² + å½“å‰user æ‹¼æˆLLMå¯ç”¨çš„messages
def assemble_messages(system_prompt: str, history: List[Message], user_text: str) -> List[Message]:
    msgs: List[Message] = [Message(role="system", content=system_prompt)]
    # åªä¿ç•™æœ€è¿‘ N è½®ï¼ˆç”± get_recent_messages æ§åˆ¶ï¼‰
    msgs.extend(history)
    msgs.append(Message(role="user", content=user_text))
    return msgs


def run_skill(skill_name: str, user_text: str, role: RoleConfig, history: list[Message], llm_client) -> SkillResult:
    if skill_name == "steelman":
        return skill_steelman.run(user_text, role, history, llm_client)
    if skill_name == "x_exam":
        return skill_x_exam.run(user_text, role, history, llm_client)
    if skill_name == "counterfactual":
        return skill_cf.run(user_text, role, history, llm_client)
    
    # Luma
    if skill_name == "luma_story":
        return luma_story.run(user_text, role, history, llm_client)
    if skill_name == "luma_reframe":
        return luma_reframe.run(user_text, role, history, llm_client)
    if skill_name == "luma_roleplay":
        return luma_roleplay.run(user_text, role, history, llm_client)

    # Aris
    if skill_name == "aris_reverse":
        return aris_reverse.run(user_text, role, history, llm_client)
    if skill_name == "aris_practice":
        return aris_practice.run(user_text, role, history, llm_client)
    if skill_name == "aris_bimap":
        return aris_bimap.run(user_text, role, history, llm_client)

    # æœªçŸ¥æŠ€èƒ½ï¼šå›é€€æ™®é€šå¯¹è¯
    return SkillResult(name="none", display_tag="", reply_text=user_text, data={})

def respond(user_text: str, state: SessionState, role: RoleConfig, llm_client, max_rounds: int = None) -> TurnResult:
    max_rounds = max_rounds or settings.MAX_ROUNDS
    
    # 1) æŠ€èƒ½ä¼˜å…ˆ
    skill_call = route(user_text=user_text, role=role, llm_client=llm_client, context_hint=None)
    
    # æœªå‘½ä¸­ï¼šå¯èƒ½æ˜¯ "__none__"
    if skill_call and skill_call.name == "__none__":
        route_debug = skill_call.args.get("debug", {})
        # æ™®é€šå¯¹è¯
        system_prompt = build_system_prompt(role)
        history = get_recent_messages(state, max_rounds=max_rounds)
        messages = assemble_messages(system_prompt, history, user_text)
        reply_text = llm_client.complete(messages, max_tokens=settings.MAX_TOKENS_RESPONSE, stream=settings.TEXT_STREAMING)
        append_turn(state, Message(role="user", content=user_text), Message(role="assistant", content=reply_text), max_rounds)

        if settings.DEBUG:
            write_log(settings.LOG_PATH, {
                "event": "chat_turn",
                "path": "llm_default",
                "user_text": user_text,
                "route_debug": route_debug,
                "reply_len": len(reply_text)
            })
        return TurnResult(reply_text=reply_text, skill=None, data={"route_debug": route_debug}, audio_bytes=None)

    # å‘½ä¸­æŠ€èƒ½ï¼ˆè§„åˆ™æˆ–åˆ†ç±»ï¼‰
    if skill_call and skill_call.name:
        history = get_recent_messages(state, max_rounds=max_rounds)
        sres = run_skill(skill_call.name, user_text, role, history, llm_client)
        append_turn(state, Message(role="user", content=user_text), Message(role="assistant", content=sres.reply_text), max_rounds)

        if settings.DEBUG:
            write_log(settings.LOG_PATH, {
                "event": "chat_turn",
                "path": "skill",
                "skill": sres.name,
                "user_text": user_text,
                "route_debug": skill_call.args.get("debug"),
                "reply_len": len(sres.reply_text)
            })
        return TurnResult(reply_text=sres.reply_text, 
                          skill=sres.name,
                          data={"display_tag": sres.display_tag, 
                                "route_debug": skill_call.args.get("debug")},
                          audio_bytes=None)

    # ç†è®ºä¸ä¼šåˆ°è¿™
    return TurnResult(reply_text="ï¼ˆæŠ±æ­‰ï¼Œè·¯ç”±å¼‚å¸¸ã€‚ï¼‰", skill=None, data={}, audio_bytes=None)


def respond_voice(audio_np, sample_rate, state: SessionState, role: RoleConfig, llm_client,
                  override_voice: Optional[str]=None, override_speed: Optional[float]=None) -> TurnResult:
    t0 = time.time()

    asr = ASRWsClient() if settings.ASR_TRANSPORT == "ws" else ASRClient()
    tts = TTSClient()

    # 1) ASR
    t_asr0 = time.time()
    asr_res = asr.transcribe(audio_np, sample_rate, audio_url=None)  # å¦‚ä½ æœ‰URLå¯ä¼ å…¥
    t_asr1 = time.time()

    user_text = asr_res.text

    # åŸ‹ç‚¹æµ‹è¯•
    if not user_text:
        write_log(settings.LOG_PATH, {"event": "voice_asr_empty", "asr_meta": asr_res.meta})

    # --- ASRå¤±è´¥å®ˆæŠ¤ï¼šä¸å†æŠŠé”™è¯¯æ–‡æ¡ˆå½“ä½œç”¨æˆ·è¾“å…¥æ¨è¿›åç»­é“¾è·¯ ---
    if not user_text.strip() or user_text.strip().startswith("ï¼ˆASRè¯·æ±‚å¤±è´¥"):
        write_log(settings.LOG_PATH, {"event":"voice_asr_failed_shortcircuit", 
                                      "asr_meta": asr_res.meta})
        return TurnResult(
            reply_text="è¯­éŸ³è¯†åˆ«æœªæˆåŠŸï¼Œè¯·é‡å½•æˆ–æ”¹ç”¨æ–‡æœ¬è¾“å…¥ã€‚\n\nè¯¦æƒ…ï¼šASRéœ€è¦æ­£ç¡®çš„éŸ³é¢‘/ç½‘ç»œï¼Œè¯·ç¨åé‡è¯•ã€‚",
            skill=None,
            data={"route_debug":{"phase":"asr_failed","meta":asr_res.meta}},
            audio_bytes=None
        )

    # 2) LLMï¼ˆå¤ç”¨æ–‡æœ¬æµç¨‹ï¼‰
    t_llm0 = time.time()
    turn_text = respond(user_text=user_text, state=state, role=role, llm_client=llm_client)
    t_llm1 = time.time()

    # 3) è§’è‰²TTSåå¥½ï¼ˆè§’è‰²è¦†ç›– > ä¼šè¯è¦†ç›– > å…¨å±€ï¼‰
    tts_prefs = getattr(role, "tts", {}) or {}
    voice = override_voice or tts_prefs.get("voice_type") or settings.TTS_VOICE
    speed = override_speed if (override_speed is not None) else tts_prefs.get("speed_ratio", settings.TTS_SPEED)

    t_tts0 = time.time()
    tts_res = tts.synthesize(turn_text.reply_text, voice_type=voice, speed_ratio=speed)

    # åŸ‹ç‚¹æµ‹è¯•
    if not getattr(tts_res, "audio_path", None):
        write_log(settings.LOG_PATH, {"event": "voice_tts_empty_path", "tts_meta": tts_res.meta})

    t_tts1 = time.time()

    total = time.time() - t0
    if settings.DEBUG:
        write_log(settings.LOG_PATH, {
            "event": "voice_turn",
            "asr_ms": int((t_asr1 - t_asr0)*1000),
            "llm_ms": int((t_llm1 - t_llm0)*1000),
            "tts_ms": int((t_tts1 - t_tts0)*1000),
            "total_ms": int(total*1000),
            "asr_meta": asr_res.meta,
            "tts_meta": tts_res.meta,
            "user_text": user_text,
            "skill": turn_text.skill,
        })

    # æ³¨æ„ï¼šè¿™é‡Œè¿”å› audio_bytes æ”¹ä¸º audio_path
    return TurnResult(reply_text=turn_text.reply_text,
                      skill=turn_text.skill,
                      data={"route_debug": turn_text.data.get("route_debug"),
                            "voice_used": voice, "speed_used": speed},
                      audio_bytes=tts_res.audio_path)  # ç”¨æ­¤å­—æ®µæ‰¿è½½è·¯å¾„


# è¯­éŸ³æ¨¡å¼ä¸‹çš„çŸ­å›å¤
def respond_short(user_text: str, state: SessionState, role: RoleConfig, llm_client) -> TurnResult:
    """
    è¯­éŸ³æ¨¡å¼ä¸‹çš„â€œçŸ­å›å¤â€ï¼šé™åˆ¶ä¸º 1-2 å¥/ä¸è¶…è¿‡ MAX_REPLY_CHARS_VOICEã€‚
    å¤ç”¨ä½ çš„ build_system_prompt / assemble_messagesï¼Œåªæ˜¯å¤šåŠ ä¸€æ®µçº¦æŸã€‚
    """
    sys_prompt = build_system_prompt(role)
    limit_note = f"ã€é‡è¦ã€‘è¯·ç”¨1-2å¥ä¸­æ–‡å›ç­”ï¼Œæ€»å­—æ•°ä¸è¶…è¿‡{settings.MAX_REPLY_CHARS_VOICE}å­—ã€‚å¦‚éœ€å±•å¼€ï¼Œè¯·æœ€åé—®ï¼šè¦ç»§ç»­å—ï¼Ÿ"
    sys_prompt = sys_prompt + "\n" + limit_note

    history = getattr(state, "history", None) or getattr(state, "turns", None) or getattr(state, "messages", None) or []
    msgs = assemble_messages(sys_prompt, history, user_text)

    # ä¹Ÿå¯åœ¨ user ä¾§å†åŠ ä¸€å¥â€œè¯·ç®€æ´å›ç­”â€
    reply = llm_client.complete(msgs, max_tokens=256, stream=False)
    
    # æ›´æ–°ä¼šè¯
    # æ”¹ä¸ºæ˜¾å¼ push åˆ° messagesï¼š
    try:
        if not hasattr(state, "messages") or state.messages is None:
            state.messages = []
        state.messages.append(Message(role="user", content=user_text))
        state.messages.append(Message(role="assistant", content=reply))
    except Exception:
        # å®¹é”™ï¼šä¸å› æ—¥å¿—å¤±è´¥å½±å“ä¸»æµç¨‹
        pass
    return TurnResult(reply_text=reply, skill=None, data={})

# å¥çº§ï¼šä¸€å¥è¯†åˆ«â†’ä¸€å¥çŸ­ç­”â†’ä¸€å¥TTSâ†’é€å¥äº§å‡º
def voice_sentence_loop(audio_np, sample_rate, state: SessionState, role: RoleConfig, llm_client, asr_client, tts_client) -> Generator[Dict[str, Any], None, None]:
    """
    ç”Ÿæˆå™¨ï¼šä¸€æ¬¡å½•éŸ³ -> ASR -> æŒ‰å¥åˆ‡ -> å¯¹æ¯å¥åšâ€œçŸ­å›å¤+TTSâ€ï¼Œé€å¥ yield åˆ° UIã€‚
    yield å­—æ®µï¼šchatbot_messagesï¼ˆåˆ—è¡¨ï¼‰ã€session_stateã€audio_pathï¼ˆæ¯å¥ä¸€ä¸ªæ–‡ä»¶ï¼‰ã€status_text
    """
    t0 = time.time()
    # ä¸€å¼€å§‹ï¼ˆæ”¶åˆ°éŸ³é¢‘ï¼‰å…ˆæç¤º
    yield {"status": "ğŸ§  æ­£åœ¨è¯†åˆ«(ASR)...", "chat_add": []}

    # 1) ASRï¼ˆæ•´æ®µè¯†åˆ«ï¼‰
    asr_t0 = time.time()
    asr_res = asr_client.transcribe(audio_np, sample_rate, audio_url=None)
    asr_t1 = time.time()
    user_text_all = (asr_res.text or "").strip()

    if not user_text_all:
        yield {
            "status": "â—æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œè¯·é‡å½•æˆ–æ”¹ç”¨æ–‡æœ¬è¾“å…¥ã€‚",
            "audio_path": None,
            "user_text": "",
            "chat_add": [("user", "ï¼ˆç©ºè¯­éŸ³ï¼‰"), ("assistant", "æ²¡å¬æ¸…å“¦ï¼Œå¯ä»¥å†è¯•ä¸€æ¬¡å—ï¼Ÿ")]
        }
        return
    
    # ASR å®Œæˆåï¼ˆæœ‰ user_textï¼‰
    yield {"status": "ğŸ¤– æ­£åœ¨æ€è€ƒ(LLM)...", "chat_add": [("user", user_text_all)]}

    # 2) åˆ†å¥
    sentences = split_for_tts(user_text_all, max_chars=settings.MAX_REPLY_CHARS_VOICE)
    yield {"status": f"ğŸ§ å·²è¯†åˆ«ï¼š{user_text_all}ï¼ˆåˆ†{len(sentences)}å¥å¤„ç†ï¼‰", "audio_path": None, "user_text": user_text_all, "chat_add": []}

    # 3) é€å¥ï¼šçŸ­å›å¤ -> TTS -> é€å¥è¾“å‡º
    for idx, sent in enumerate(sentences, 1):
        step_t0 = time.time()
        # 3.1 åˆ†ç±»ï¼ˆå°æ¨¡å‹å…œåº•ï¼›ä½ å·²æœ‰ classifyï¼Œå¯é€‰æ¥å…¥ï¼‰
        # cls = llm_client.classify(sent, schema=...)
        # å…ˆçœç•¥ï¼Œç›´æ¥çŸ­å›å¤
        # 3.2 çŸ­å›å¤
        turn = respond_short(user_text=sent, state=state, role=role, llm_client=llm_client)
        # LLM å¾—åˆ° reply åï¼Œé©¬ä¸Šæç¤º
        yield {"status": "ğŸ”Š æ­£åœ¨åˆæˆ(TTS)...", "chat_add": []}
        # 3.3 TTSï¼ˆå•å¥ï¼‰
        tts_res = tts_client.synthesize(turn.reply_text,
                                        voice_type=(getattr(role, "tts", {}) or {}).get("voice_type"),
                                        speed_ratio=(getattr(role, "tts", {}) or {}).get("speed_ratio"))
        audio_path = tts_res.audio_path
        
        if audio_path:
            # ç»Ÿä¸€æˆæ­£æ–œæ ï¼ŒGradio/æµè§ˆå™¨å¯¹ Windows è·¯å¾„æ›´å‹å¥½
            audio_path = os.path.normpath(audio_path).replace("\\", "/")
        # 3.4 é€å¥æ¨é€
        yield {
            "status": f"ğŸ—£ï¸ ç¬¬{idx}/{len(sentences)}å¥ï¼š{sent}",
            "audio_path": audio_path,   # gr.Audio å¯ç›´æ¥æ’­
            "user_text": sent,
            "chat_add": [("assistant", turn.reply_text)]
        }
        # 3.5 é—´éš”ï¼ˆè®©å‰ç«¯æœ‰æ—¶é—´æ’­æ”¾ï¼‰- å¯ç”±å‰ç«¯æ§åˆ¶ï¼Œè¿™é‡Œä¸sleep

    total = int((time.time() - t0) * 1000)
    write_log(settings.LOG_PATH, {
        "event": "voice_sentence_loop_done",
        "asr_ms": int((asr_t1-asr_t0)*1000),
        "total_ms": total,
        "n_sent": len(sentences)
    })